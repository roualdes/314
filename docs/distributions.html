<!DOCTYPE html>
<html lang="en">
  

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width,minimum-scale=1">

  <title>Distributions</title>
  <meta name="description" content="Distributions">

  <link rel="canonical" href="/distributions.html">
  <link rel="alternate" type="application/rss+xml" title="MATH 314 Lecture Notes" href="/feed.xml">

  <meta property="og:url"         content="/distributions.html" />
<meta property="og:type"        content="article" />
<meta property="og:title"       content="Distributions" />
<meta property="og:description" content="Distributions" />
<meta property="og:image"       content="" />


  <script type="application/ld+json">
  {
  "@context": "http://schema.org",
  "@type": "NewsArticle",
  "mainEntityOfPage":
    "/distributions.html",
  "headline":
    "Distributions",
  "datePublished":
    "2019-10-30T08:56:09-07:00",
  "dateModified":
    "2019-10-30T08:56:09-07:00",
  "description":
    "Distributions",
  "author": {
    "@type": "Person",
    "name": "Edward A. Roualdes"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Data 100 at UC Berkeley",
    "logo": {
      "@type": "ImageObject",
      "url": "",
      "width": 60,
      "height": 60
    }
  },
  "image": {
    "@type": "ImageObject",
    "url": "",
    "height": 60,
    "width": 60
  }
}

  </script>
  <link rel="stylesheet" href="/assets/css/styles.css">
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css ">
  <link rel="apple-touch-icon" sizes="57x57" href="/apple-touch-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="60x60" href="/apple-touch-icon-60x60.png">
  <link rel="apple-touch-icon" sizes="72x72" href="/apple-touch-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="76x76" href="/apple-touch-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="114x114" href="/apple-touch-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="120x120" href="/apple-touch-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="144x144" href="/apple-touch-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/apple-touch-icon-152x152.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon-180x180.png">

  <!-- <link rel="manifest" href="/manifest.json"> -->
  <!-- <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#efae0a"> -->
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="msapplication-TileImage" content="/mstile-144x144.png">
  <meta name="theme-color" content="#233947">

  <!-- Favicon -->
  <link rel="shortcut icon" type="image/x-icon" href="/images/logo/favicon.ico">

  <!-- MathJax Config -->
  <!-- Allow inline math using $ and automatically break long math lines -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true,
        processEnvironments: true
    },
    CommonHTML: {
        linebreaks: {
            automatic: true,
        },
    },
});
</script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_CHTML' async></script>

  <!-- DOM updating function -->
  <script>
const runWhenDOMLoaded = cb => {
  if (document.readyState != 'loading') {
    cb()
  } else if (document.addEventListener) {
    document.addEventListener('DOMContentLoaded', cb)
  } else {
    document.attachEvent('onreadystatechange', function() {
      if (document.readyState == 'complete') cb()
    })
  }
}

// Helper function to init things quickly
initFunction = function(myfunc) {
  runWhenDOMLoaded(myfunc);
  document.addEventListener('turbolinks:load', myfunc);
};
</script>

  <!-- Define some javascript variables that will be useful in other javascript -->
  <script>
    const site_basename = '';
  </script>

  <!-- Add AnchorJS to let headers be linked -->
  <script src="/assets/js/anchor.min.js"  type="text/javascript"></script>
  <script>

initFunction(function () {
    anchors.add("main h1, main h2, main h3, main h4")
});

</script>

  <!-- Include Turbolinks to make page loads fast -->
  <!-- https://github.com/turbolinks/turbolinks -->
  <script src="/assets/js/turbolinks.js" async></script>
  <meta name="turbolinks-cache-control" content="no-cache">

  <!-- Load nbinteract for widgets -->
  

  <!-- Load Thebelab for interactive widgets -->
  <!-- Include Thebelab for interactive code if it's enabled -->



  <!-- Load the auto-generating TOC -->
  <script src="/assets/js/tocbot.min.js"  type="text/javascript"></script>
  <script>
var initToc = function () {
  tocbot.init({
    tocSelector: 'nav.onthispage',
    contentSelector: '.c-textbook__content',
    headingSelector: 'h2, h3',
    orderedList: false,
    collapseDepth: 6,
    listClass: 'toc__menu',
    activeListItemClass: "",  // Not using
    activeLinkClass: "", // Not using
  });
  tocbot.refresh();
}
initFunction(initToc);
</script>

  <!-- Google analytics -->
  <script src="/assets/js/ga.js" async></script>

  <!-- Clipboard copy button -->
  <script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js" async></script>

  <!-- Load JS that depends on site variables -->
  <script>
/**
 * Set up copy/paste for code blocks
 */
const codeCellId = index => `codecell${index}`

const clipboardButton = id =>
  `<a id="copy-button-${id}" class="btn copybtn o-tooltip--left" data-tooltip="Copy" data-clipboard-target="#${id}">
    <img src="/assets/images/copy-button.svg" alt="Copy to clipboard">
  </a>`

// Clears selected text since ClipboardJS will select the text when copying
const clearSelection = () => {
  if (window.getSelection) {
    window.getSelection().removeAllRanges()
  } else if (document.selection) {
    document.selection.empty()
  }
}

// Changes tooltip text for two seconds, then changes it back
const temporarilyChangeTooltip = (el, newText) => {
  const oldText = el.getAttribute('data-tooltip')
  el.setAttribute('data-tooltip', newText)
  setTimeout(() => el.setAttribute('data-tooltip', oldText), 2000)
}

const addCopyButtonToCodeCells = () => {
  // If ClipboardJS hasn't loaded, wait a bit and try again. This
  // happens because we load ClipboardJS asynchronously.
  if (window.ClipboardJS === undefined) {
    setTimeout(addCopyButtonToCodeCells, 250)
    return
  }

  const codeCells = document.querySelectorAll('div.c-textbook__content > div.highlighter-rouge > div.highlight > pre, div.input_area pre')
  codeCells.forEach((codeCell, index) => {
    const id = codeCellId(index)
    codeCell.setAttribute('id', id)
    if (document.getElementById("copy-button" + id) == null) {
      codeCell.insertAdjacentHTML('afterend', clipboardButton(id));
    }
  })

  const clipboard = new ClipboardJS('.copybtn')
  clipboard.on('success', event => {
    clearSelection()
    temporarilyChangeTooltip(event.trigger, 'Copied!')
  })

  clipboard.on('error', event => {
    temporarilyChangeTooltip(event.trigger, 'Failed to copy')
  })

  // Get rid of clipboard before the next page visit to avoid memory leak
  document.addEventListener('turbolinks:before-visit', () =>
    clipboard.destroy()
  )
}

initFunction(addCopyButtonToCodeCells);
</script>


  <!-- Hide cell code -->
  <script>
    /**
    Add buttons to hide code cells
    */


    var setCodeCellVisibility = function (inputField, kind) {
        // Update the image and class for hidden
        var id = inputField.getAttribute('data-id');
        var codeCell = document.querySelector(`#${id} div.highlight`);

        if (kind === "visible") {
            codeCell.classList.remove('hidden');
            inputField.checked = true;
        } else {
            codeCell.classList.add('hidden');
            inputField.checked = false;
        }
    }

    var toggleCodeCellVisibility = function (event) {
        // The label is clicked, and now we decide what to do based on the input field's clicked status
        if (event.target.tagName === "LABEL") {
            var inputField = event.target.previousElementSibling;
        } else {
            // It is the span inside the target
            var inputField = event.target.parentElement.previousElementSibling;
        }

        if (inputField.checked === true) {
            setCodeCellVisibility(inputField, "visible");
        } else {
            setCodeCellVisibility(inputField, "hidden");
        }
    }


    // Button constructor
    const hideCodeButton = id => `<input class="hidebtn" type="checkbox" id="hidebtn${id}" data-id="${id}"><label title="Toggle cell" for="hidebtn${id}" class="plusminus"><span class="pm_h"></span><span class="pm_v"></span></label>`

    var addHideButton = function () {
        // If a hide button is already added, don't add another
        if (document.querySelector('div.hidecode input') !== null) {
            return;
        }

        // Find the input cells and add a hide button
        document.querySelectorAll('div.input_area').forEach(function (item, index) {
            if (!item.classList.contains("hidecode")) {
                // Skip the cell if it doesn't have a hidecode class
                return;
            }

            const id = codeCellId(index)
            item.setAttribute('id', id);
            // Insert the button just inside the end of the next div
            item.querySelector('div').insertAdjacentHTML('beforeend', hideCodeButton(id))

            // Set up the visibility toggle
            hideLink = document.querySelector(`#${id} div.highlight + input + label`);
            hideLink.addEventListener('click', toggleCodeCellVisibility)
        });
    }


    // Initialize the hide buttos
    var initHiddenCells = function () {
        // Add hide buttons to the cells
        addHideButton();

        // Toggle the code cells that should be hidden
        document.querySelectorAll('div.hidecode input').forEach(function (item) {
            setCodeCellVisibility(item, 'hidden');
            item.checked = true;
        })
    }

    initFunction(initHiddenCells);

</script>

  <!-- Load custom website scripts -->
  <script src="/assets/js/scripts.js" async></script>

  <!-- Load custom user CSS and JS  -->
  <script src="/assets/custom/custom.js" async></script>
  <link rel="stylesheet" href="/assets/custom/custom.css">

  <!-- Update interact links w/ REST param, is defined in includes so we can use templates -->
  

  <!-- Lunr search code - will only be executed on the /search page -->
  <script src="/assets/js/lunr/lunr.min.js" type="text/javascript"></script>
  <script>var initQuery = function() {
  // See if we have a search box
  var searchInput = document.querySelector('input#lunr_search');
  if (searchInput === null) {
    return;
  }

  // Function to parse our lunr cache
  var idx = lunr(function () {
    this.field('title')
    this.field('excerpt')
    this.field('categories')
    this.field('tags')
    this.ref('id')

    this.pipeline.remove(lunr.trimmer)

    for (var item in store) {
      this.add({
        title: store[item].title,
        excerpt: store[item].excerpt,
        categories: store[item].categories,
        tags: store[item].tags,
        id: item
      })
    }
  });

  // Run search upon keyup
  searchInput.addEventListener('keyup', function () {
    var resultdiv = document.querySelector('#results');
    var query = document.querySelector("input#lunr_search").value.toLowerCase();
    var result =
      idx.query(function (q) {
        query.split(lunr.tokenizer.separator).forEach(function (term) {
          q.term(term, { boost: 100 })
          if(query.lastIndexOf(" ") != query.length-1){
            q.term(term, {  usePipeline: false, wildcard: lunr.Query.wildcard.TRAILING, boost: 10 })
          }
          if (term != ""){
            q.term(term, {  usePipeline: false, editDistance: 1, boost: 1 })
          }
        })
      });

      // Empty the results div
      while (resultdiv.firstChild) {
        resultdiv.removeChild(resultdiv.firstChild);
      }

    resultdiv.insertAdjacentHTML('afterbegin', '<p class="results__found">'+result.length+' Result(s) found</p>');
    for (var item in result) {
      var ref = result[item].ref;
      if(store[ref].teaser){
        var searchitem =
          '<div class="list__item">'+
            '<article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">'+
              '<h2 class="archive__item-title" itemprop="headline">'+
                '<a href="'+store[ref].url+'" rel="permalink">'+store[ref].title+'</a>'+
              '</h2>'+
              '<div class="archive__item-teaser">'+
                '<img src="'+store[ref].teaser+'" alt="">'+
              '</div>'+
              '<p class="archive__item-excerpt" itemprop="description">'+store[ref].excerpt.split(" ").splice(0,20).join(" ")+'...</p>'+
            '</article>'+
          '</div>';
      }
      else{
    	  var searchitem =
          '<div class="list__item">'+
            '<article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">'+
              '<h2 class="archive__item-title" itemprop="headline">'+
                '<a href="'+store[ref].url+'" rel="permalink">'+store[ref].title+'</a>'+
              '</h2>'+
              '<p class="archive__item-excerpt" itemprop="description">'+store[ref].excerpt.split(" ").splice(0,20).join(" ")+'...</p>'+
            '</article>'+
          '</div>';
      }
      resultdiv.insertAdjacentHTML('beforeend', searchitem);
    }
  });
};

initFunction(initQuery);
</script>
</head>

  <body>
    <!-- .js-show-sidebar shows sidebar by default -->
    <div id="js-textbook" class="c-textbook js-show-sidebar">
      



<nav id="js-sidebar" class="c-textbook__sidebar">
  <a href="https://jupyter.org/jupyter-book/"><img src="/images/logo/logo.png" class="textbook_logo" id="sidebar-logo" data-turbolinks-permanent/></a>
  <h2 class="c-sidebar__title">MATH 314 Lecture Notes</h2>
  <ul class="c-sidebar__chapters">
    
      
      

      
      

      
      
      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/intro.html"
        >
          
          Home
        </a>

        
      </li>

      
    
      
      

      
      

      
      
      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="https://github.com/roualdes/314"
        >
          
          GitHub repository
        </a>

        
      </li>

      
    
      
      
        <li class="c-sidebar__chapter"><a class="c-sidebar__entry" href="/search.html">Search</a></li>
        
      
      
        <li class="c-sidebar__divider"></li>
        
      
      

      
      

      
      
      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/probability.html"
        >
          
            1.
          
          Probability
        </a>

        
      </li>

      
    
      
      

      
      

      
      
      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/bernoulli.html"
        >
          
            2.
          
          Bernoulli Distribution
        </a>

        
      </li>

      
    
      
      

      
      

      
      
      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry c-sidebar__entry--active"
          href="/distributions.html"
        >
          
            3.
          
          Distributions
        </a>

        
      </li>

      
    
      
      

      
      

      
      
      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/gamma.html"
        >
          
            4.
          
          Gamma Distribution
        </a>

        
      </li>

      
    
      
      

      
      

      
      
      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/normal.html"
        >
          
            5.
          
          Normal Distribution
        </a>

        
      </li>

      
    
      
      

      
      

      
      
      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/bootstrap.html"
        >
          
            6.
          
          Bootstrap
        </a>

        
      </li>

      
    
      
      

      
      

      
      
      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/normal_linear_models/introduction.html"
        >
          
            7.
          
          Normal Linear Models
        </a>

        

          
          
          
          

          

          <ul class="c-sidebar__sections u-hidden-visually">
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/normal_linear_models/one_mean.html"
                >
                  
                    7.1
                  
                  One Mean
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/normal_linear_models/simple_reg.html"
                >
                  
                    7.2
                  
                  Simple Linear Regression
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/normal_linear_models/two_means.html"
                >
                  
                    7.3
                  
                  Two Means
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/normal_linear_models/k_means.html"
                >
                  
                    7.4
                  
                  k Means
                </a>

                
                

              </li>
              
            
              
              

              <li class="c-sidebar__section">
                <a class="c-sidebar__entry "
                  href="/normal_linear_models/multiple_linear_reg.html"
                >
                  
                    7.5
                  
                  Multiple Linear Regression
                </a>

                
                

              </li>
              
            
          </ul>
        
      </li>

      
    
      
      

      
      

      
      
      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/references.html"
        >
          
            8.
          
          References
        </a>

        
      </li>

      
    
      
      

      
      

      
      
      <li class="c-sidebar__chapter">
        <a class="c-sidebar__entry "
          href="/glossary.html"
        >
          
            9.
          
          Glossary
        </a>

        
      </li>

      
    
  </ul>
  <p class="sidebar_footer">Powered by <a href="https://github.com/jupyter/jupyter-book">Jupyter Book</a></p>
</nav>

      
      <!-- Empty sidebar placeholder that we'll auto-fill with javascript -->
      <aside class="sidebar__right">
          <header><h4 class="nav__title"><i class="fa fa-list"></i>   On this page</h4></header>
          <nav class="onthispage">
          </nav>
      </aside>
      
      <main class="c-textbook__page" tabindex="-1">
          <div class="o-wrapper">
            <div class="c-sidebar-toggle">
  <!-- We show the sidebar by default so we use .is-active -->
  <button
    id="js-sidebar-toggle"
    class="hamburger hamburger--arrowalt is-active"
  >
    <span class="hamburger-box">
      <span class="hamburger-inner"></span>
    </span>
    <span class="c-sidebar-toggle__label">Toggle Sidebar</span>
  </button>
</div>

            
<div class="buttons">






</div>


            <div class="c-textbook__content">
              <h1 id="distributions">Distributions</h1>

<h2 id="introduction">Introduction</h2>

<p>This section will begin to formalize the connection between random variables, probability density functions, and population parameters.  We generally use language like the random variable $X$ follows a named distribution, which has a probability density function defined by, possibly many, parameters.  Hence, the word distribution in some sense is just the name the binds random variables, probability density functions, and parameters together.</p>

<h2 id="warm-up">Warm Up</h2>

<p>Before we look at two common named population parameters, let’s introduce a few new words that we’ll use throughout this section.</p>

<ul>
  <li><strong>support</strong>: The set of values a random variable might assume, and equally the set of values a random variable’s probability density function is defined over.<br />
For example, the support of $X \sim \text{Uniform}(1, 6)$ is the integers from $1$ to $6$ inclusive.</li>
  <li><strong>expected value</strong>: A population-level measure of center for a random variable.<br />
For example, $3.5$ for a fair die.</li>
  <li><strong>variance</strong>: A population-level measure of variability for a random variable.</li>
  <li><strong>standard deviation</strong>: The square root of the variance.</li>
</ul>

<h2 id="random-variables">Random Variables</h2>

<p>A random variable is a function from a set of all possible outcomes,
named the sample space, to exactly one real number.  We often
assume that random variables follow named distributions, e.g. $Y \sim
\text{Uniform}(a, b)$ where $a &lt; b$, or $X \sim \text{Bernoulli}(p)$ where $p
\in [0, 1]$.  Named distributions are common because they often
abstractly represent processes in the world worth measuring.  Based on
the outcome of the process of interest, we calculate probabilities
for a random variable that follows a specific distribution.</p>

<p>The Uniform distribution represents well rolling die.  Much of the
probabilities surrounding gambling are found by assuming random
variables follow various Uniform distributions.  Ignoring payouts, roulette is essentially a random variable $X \sim \text{Uniform}(1, 36)$.</p>

<p>The Bernoulli distirbution represents well any process that has two
mutually exclusive outcomes with a fixed probability of “success.”
Anything from unfair coins to the outcomes of elections are modeled
with Bernoulli random variables.</p>

<p>These are not the only random variables, nor are random variables
restricted to countable outcomes.  Discrete random variables are
restrictued to countable outcomes and continous random variables are
the extension to uncountable outcomes.  Discrete random variables take
on non-negative mass or probability at single points in the
support of the random variable, and thus have probability mass
functions.  On the other hand, continuous random variables have
probability density functions, since zero mass occurs at distinct
points in the support of the random variable.  These lecture notes
will only use the name probability density functions, even when
referring to discrete random variables.</p>

<p>Before providing a long list of some other common named distributions, we will discuss the mean and variance of a random variable.  These quantities describe a measure of center and a measure of spread of random variables.  Recall, statistics uses data to estimate population parameters.  The mean and variance of a random variable are two of the more commonly estimated quantities that describe a population.  With a data set in hand, the sample mean (add up all the data divide by the number of data points) is an approximation of the mean of a random variable.  With a data set in hand, the measure of spread called the variance is an approximation of the variance of a random variable.</p>

<div class="cell code_cell">
  <div class="input_area">
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">bplot</span> <span class="k">as</span> <span class="n">bp</span>

<span class="n">bp</span><span class="o">.</span><span class="n">LaTeX</span><span class="p">()</span>
<span class="n">bp</span><span class="o">.</span><span class="n">dpi</span><span class="p">(</span><span class="mi">300</span><span class="p">)</span>

</code></pre></div>    </div>
  </div>

</div>

<h2 id="mean-of-a-random-variable">Mean of a Random Variable</h2>

<p>Think back to our discrete random variable that represented rolling a
single fair die, $X \sim \text{Uniform}(1, 6)$.  We formalized the
mathematical notation $P(X \in {2,4,6}) = 1/2$ by imagining
rolling the same fair die an infinite number of times and dividing the
number of times either $2, 4$, or $6$ turns up by the total number of
rolls.  Next, we will formalize, in a similar notion, the idea of the mean of a random variable.</p>

<p>The expected value describes a measure of center of a random
variable.  This is related to but not exactly, the same thing as, the sample
mean where you add up all the numbers and divide by how every many
numbers there are.  The expected value does not describe data.  The expected value instead describes a measure of
center of the probaility density function for a random variable.</p>

<p>For the discrete random variable $X \sim \text{Uniform}(1, 6)$ the probability density function is displayed below.  More generally, as uniform implies sameness, mathematically the probability density function is the same for all arguments</p>

<script type="math/tex; mode=display">uniform(x|a, b) = \frac{1}{b - a + 1}</script>

<p>for $x \in \{a, a+1, \ldots, b-1, b\}$.  Notice that the random variable is only defined for integer values between $a$ and $b$ inclusive.  These values make up the <strong>support</strong> of the random variable. Think of the support as the values for which the probability density function is positive.</p>

<div class="cell code_cell">
  <div class="input_area">
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">fx</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">6</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s">'x'</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="s">'f'</span><span class="p">:</span> <span class="n">fx</span><span class="p">})</span>

<span class="n">bp</span><span class="o">.</span><span class="n">point</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'x'</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s">'f'</span><span class="p">])</span>
<span class="n">bp</span><span class="o">.</span><span class="n">labels</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'$x$'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'uniform$(x|1,6)$'</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>

</code></pre></div>    </div>
  </div>

  <div class="output_wrapper">
    <div class="output_subarea">

      <div class="output_data_text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x11f3db080&gt;
</code></pre></div>      </div>

    </div>
  </div>
  <div class="output_wrapper">
    <div class="output_subarea">

      <p class="output_png"><img src="images/distributions_4_1.png" alt="png" /></p>

    </div>
  </div>
</div>

<h3 id="example">Example</h3>

<p>Since population mean describes a measure of center, and the probability density function takes on the same value $1/6$ at each value in the support ${1, 2, 3, 4, 5, 6}$, the expected value must be the value in the middle of the support, namely $3.5$.  Formally, we read $\mathbb{E}(X) = 3.5$ as the <strong>expected value</strong> of the random variable $X$ is $3.5$.  As the sample mean is to data, the expected value is to a random variable.</p>

<p>More formally, the expected value of $X \sim \text{Uniform}(a, b)$ is</p>

<script type="math/tex; mode=display">\mathbb{E}(X) = \sum_{x = a}^b x * \text{uniform}(x|a,b) = \sum_{x = a}^b x * \frac{1}{b - a + 1}.</script>

<p>In R, we can apply this formula to $X \sim \text{Uniform}(1,6)$,</p>

<div class="cell code_cell">
  <div class="input_area">
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">a</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">b</span> <span class="o">=</span> <span class="mi">6</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">fx</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="n">b</span> <span class="o">-</span> <span class="n">a</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="nb">sum</span><span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="n">fx</span><span class="p">)</span> <span class="c"># E(X)</span>

</code></pre></div>    </div>
  </div>

  <div class="output_wrapper">
    <div class="output_subarea">

      <div class="output_data_text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>3.5
</code></pre></div>      </div>

    </div>
  </div>
</div>

<p>Notice that the we are simply weighting each value in the support of the random variable by the probability density function evaluated at each value in the support.  The expected value is to be thought of as the value you’d get by taking the sample mean of the outcomes produced by infinitely rolling a fair die.  Let’s approximate this process in R,</p>

<div class="cell code_cell">
  <div class="input_area">
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">N</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">1e3</span><span class="p">)</span>
<span class="n">die</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">N</span><span class="p">)</span>
<span class="n">flips</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s">'flip'</span><span class="p">:</span> <span class="n">flips</span><span class="p">,</span>
                   <span class="s">'m'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">die</span><span class="p">)</span><span class="o">/</span><span class="n">flips</span><span class="p">})</span>

<span class="n">bp</span><span class="o">.</span><span class="n">line</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'flip'</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s">'m'</span><span class="p">])</span>
<span class="n">bp</span><span class="o">.</span><span class="n">line_h</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mf">3.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'black'</span><span class="p">)</span>
<span class="n">bp</span><span class="o">.</span><span class="n">labels</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'flip'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'$</span><span class="err">\</span><span class="s">hat{E}(X)$'</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>

</code></pre></div>    </div>
  </div>

  <div class="output_wrapper">
    <div class="output_subarea">

      <div class="output_data_text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x12152bba8&gt;
</code></pre></div>      </div>

    </div>
  </div>
  <div class="output_wrapper">
    <div class="output_subarea">

      <p class="output_png"><img src="images/distributions_9_1.png" alt="png" /></p>

    </div>
  </div>
</div>

<p><strong>DEFINITION</strong>.  Let $X \sim F$, where $F$ is the name of a distribution. The expected value of a random variable is</p>

<script type="math/tex; mode=display">\mathbb{E}(X) = \int_{\mathbb{R}} x\,d\text{F}(x).</script>

<p>The fancy integral here is just to remind you that for discrete random variables, the integral becomes a sum, as above, and for continuous random variables the integral stays.  In both cases, the sum/integral ranges over the support of the random variable and the summand/integrand is the product of $x$ and the probability density function.</p>

<h2 id="variance-and-standard-deviation-of-a-random-variable">Variance and Standard Deviation of a Random Variable</h2>

<p>Where the mean is a measure of center of a random variable, the variance is a measure of spread.  Specifically, the variance measures squared distance from the mean, again weighted by the probability density function.</p>

<p><strong>DEFINITION</strong>.  Let $X \sim F$, where $F$ is the name of a distribution function with mean $\mu = \mathbb{E}(X)$, the variance of $X$ is</p>

<script type="math/tex; mode=display">\mathbb{V}(X) = \int_{\mathbb{R}} (x - \mathbb{E}(X))^2 \, dF(x).</script>

<p><strong>DEFINITION</strong>. Let $X \sim F$, where $F$ is the name of a distribution function with variance $\mathbb{V}(X)$, the standard deviation of $X$ is</p>

<script type="math/tex; mode=display">\mathbb{D}(X) = \sqrt{\mathbb{V}(X)}.</script>

<p>The standard deviation is another measure of spread, like the variance, but the standard deviation is in the same units as the mean.</p>

<h3 id="example-1">Example</h3>

<p>In Python, we can apply this formula to $X \sim \text{Uniform}(1,6)$ by first calculating the expected value $\mathbb{E}(X)$,</p>

<div class="cell code_cell">
  <div class="input_area">
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">a</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">b</span> <span class="o">=</span> <span class="mi">6</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">fx</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="n">b</span> <span class="o">-</span> <span class="n">a</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">m</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="n">fx</span><span class="p">)</span>
<span class="n">v</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">m</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">fx</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>

</code></pre></div>    </div>
  </div>

  <div class="output_wrapper">
    <div class="output_subarea">

      <div class="output_data_text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1.707825127659933
</code></pre></div>      </div>

    </div>
  </div>
</div>

<h3 id="example-2">Example</h3>

<p>Assume $X \sim \text{Bernoulli}(p)$.  If you work through the math for the variance, then you end up at an equation that we can almost make sense of.</p>

<script type="math/tex; mode=display">\mathbb{V}(X) = p(1 - p)</script>

<p>Let’s plot this.</p>

<div class="cell code_cell">
  <div class="input_area">
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">101</span><span class="p">)</span>
<span class="n">fp</span> <span class="o">=</span> <span class="n">p</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p</span><span class="p">)</span>
<span class="n">bp</span><span class="o">.</span><span class="n">curve</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">fp</span><span class="p">)</span>
<span class="n">bp</span><span class="o">.</span><span class="n">labels</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'$p$'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'$f(p)$'</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>

</code></pre></div>    </div>
  </div>

  <div class="output_wrapper">
    <div class="output_subarea">

      <div class="output_data_text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x1216598d0&gt;
</code></pre></div>      </div>

    </div>
  </div>
  <div class="output_wrapper">
    <div class="output_subarea">

      <p class="output_png"><img src="images/distributions_16_1.png" alt="png" /></p>

    </div>
  </div>
</div>

<p>We can infer that the variance is maximized at p = 0.5; the math isn’t too difficult, try.  This says that for a coin has the most variability (e.g. bounces back and forth between heads and tails the most) when it is a fair coin.  This makes sense.  An extremely biased coin, say $p = 0.001$ will very often come up tails, and rarely fall on heads.</p>

<p>It takes some time to understand the fancy integral notation above.  There are a few ideas that you should keep in mind when working with the definitions of $\mathbb{E}(X)$ and $\mathbb{V}(X)$:</p>

<ol>
  <li>if the random variable $X$ is discrete then the integral is really a sum,</li>
  <li>the summand/integrand is defined as the product of the function that shows up in front of $dF(x)$ times the probability density function of $X$, and</li>
  <li>the summand/integrand is evaluated at each value in the support of the random variable $X$.</li>
</ol>

<h1 id="common-distributions">Common Distributions</h1>

<p>There are a few moving pieces to keep in mind while scanning or
referencing the list of distributions below.</p>

<ol>
  <li>
    <p>Each distribution presented is a generally accepted statistical
  abstraction of a common process in the world.  Different sets of the
  real numbers $\mathbb{R}$ will support different real world
  processes.  For instance, when measuring time until an event
  (Exponential), only positively valued real numbers are relevant.
  When measuring counting events (Poisson), only positive integers are
  relevant.  This idea is known as the <strong>support</strong> of the probability
  density function.  The support describes the set of possible values
  a random variable might take on.</p>
  </li>
  <li>
    <p>The variables following the pipe in the function signature are
generally referred to as parameters.  For instance, $a$ and $b$ of
the uniform distribution define the support of the random variable.
For a discrete uniform random variable meant to describe the
process of rolling a die, $a = 1$ and $b = 6$.  These parameters
constitue some, but not all, of the population parameters that are
estimated from a sample.  The parameter $\beta$ in the Exponential
distribution describes the rate at which events occur in time or space.</p>
  </li>
  <li>
    <p>These lecture notes focus on the likelihood function as a means to
estimate population parameters from a sample.  This method will
work simply for any probability density function who’s
support does not depend on the parameters.  However, the maximum
likelihood estimator for the uniform distribution will take more
careful thought than it will direct application of calculus.</p>
  </li>
</ol>

<h2 id="discrete-distributions">Discrete Distributions</h2>

<h3 id="uniform">Uniform</h3>

<p>For $X \sim \text{Uniform}(a, b)$ where $a &lt; b$, $X$ has probability
density function</p>

<script type="math/tex; mode=display">\text{uniform}(x | a, b) = \frac{1}{b - a + 1}</script>

<p>for $x \in \{a, a+1, \ldots, b - 1, b \}$.</p>

<script type="math/tex; mode=display">\mathbb{E}(X) = \frac{b+a}{2} \quad \text{ and } \quad \mathbb{V}(X) = \frac{(b - a + 1)^2 - 1}{12}</script>

<h3 id="bernoulli">Bernoulli</h3>

<p>For $X \sim \text{Bernoulli}(p)$ where $p \in [0, 1]$, $X$ has
probability density function</p>

<script type="math/tex; mode=display">\text{bernoulli}(x | p) = p^x (1 - p)^{1 - x}</script>

<p>for $x \in \{0, 1\}$.</p>

<script type="math/tex; mode=display">\mathbb{E}(X) = p \quad \text{ and } \quad \mathbb{V}(X) = p(1 - p)</script>

<h3 id="geometric">Geometric</h3>

<p>For $X \sim \text{Geometric}(p)$ where $p \in [0, 1]$, $X$ has
probability density function</p>

<script type="math/tex; mode=display">\text{geometric}(x | p) = p (1 - p)^{x - 1}</script>

<p>for $x \in \{1, 2, \ldots \}$.</p>

<script type="math/tex; mode=display">\mathbb{E}(X) = 1/p \quad \text{ and } \quad \mathbb{V}(X) = \frac{1 - p}{p^2}</script>

<h3 id="binomial">Binomial</h3>

<p>For $X \sim \text{Binomial}(K, p)$ where $K \in \mathbb{N} <br />
\{0\}$ and $p \in [0, 1]$, $X$ has probability density funciton</p>

<script type="math/tex; mode=display">\text{binomial}(x | K, p) = {K \choose x} p^x (1 - p)^{K - x}</script>

<p>for $x \in \{0, 1, \ldots, K \}$.</p>

<script type="math/tex; mode=display">\mathbb{E}(X) = Kp \quad \text{ and } \quad \mathbb{V}(X) = Kp(1 - p)</script>

<h3 id="poisson">Poisson</h3>

<p>For $X \sim \text{Poisson}(\lambda)$ where $\lambda &gt; 0$, $X$ has
probability density function</p>

<script type="math/tex; mode=display">\text{poisson}(x | \lambda) = \frac{e^{-\lambda}\lambda^x}{x!}</script>

<p>for $x \in \mathbb{N}$.</p>

<script type="math/tex; mode=display">\mathbb{E}(X) = \lambda \quad \text{ and } \quad \mathbb{V}(X) = \lambda</script>

<h2 id="continuous-distributions">Continuous Distributions</h2>

<h3 id="uniform-1">Uniform</h3>

<p>For $X \sim \text{Uniform}(a, b)$ where $a &lt; b$, $X$ has probability
density function</p>

<script type="math/tex; mode=display">\text{uniform}(x | a, b) = \frac{1}{b - a}</script>

<p>for $x \in [a, b]$.</p>

<script type="math/tex; mode=display">\mathbb{E}(X) = \frac{b+a}{2} \quad \text{ and } \quad \mathbb{V}(X) = \frac{(b - a)^2}{12}</script>

<h3 id="beta">Beta</h3>

<p>For $X \sim \text{Beta}(\alpha, \beta)$ where $\alpha &gt; 0$ and
$\beta &gt; 0$, $X$ has probability density function</p>

<script type="math/tex; mode=display">\text{beta}(x | \alpha, \beta) = \frac{\Gamma(\alpha +
\beta)}{\Gamma(\alpha)\Gamma(\beta)}x^{\alpha - 1}(1 - x)^{\beta -
1}</script>

<p>for $x \in [0, 1]$.</p>

<script type="math/tex; mode=display">\mathbb{E}(X) = \frac{\alpha}{\alpha + \beta} \quad \text{ and } \quad \mathbb{V}(X) = \frac{\alpha\beta}{(\alpha + \beta)^2(\alpha + \beta + 1)}</script>

<h3 id="exponential">Exponential</h3>

<p>For $X \sim \text{Exponential}(\beta)$ where $\beta &gt; 0$, $X$ has
probability density function</p>

<script type="math/tex; mode=display">\text{exponential}(x | \beta) = \beta\exp{ (-\beta x) }</script>

<p>for $x \geq 0$.</p>

<script type="math/tex; mode=display">\mathbb{E}(X) = 1 / \beta \quad \text{ and } \quad \mathbb{V}(X) = 1 / \beta^2</script>

<h3 id="gamma">Gamma</h3>

<p>For $X \sim \text{Gamma}(\alpha, \beta)$ where $\alpha &gt; 0$ and
$\beta &gt; 0$, $X$ has probability density function</p>

<script type="math/tex; mode=display">\text{gamma}(x | \alpha, \beta) =
\frac{\beta^{\alpha}}{\Gamma(\alpha)} x^{\alpha - 1} \exp{ (-\beta x) }</script>

<p>for $x \geq 0$.</p>

<script type="math/tex; mode=display">\mathbb{E}(X) = \alpha / \beta \quad \text{ and } \quad \mathbb{V}(X) = \alpha / \beta^2</script>

<h3 id="normal">Normal</h3>

<p>For $X \sim \text{Normal}(\mu, \sigma)$ where $\mu \in \mathbb{R}$ and
$\sigma &gt; 0$, $X$ has probability density function</p>

<script type="math/tex; mode=display">\text{normal}(x | \mu, \sigma) = (2\sigma^2)^{-1/2} \exp{ \left(
\frac{-(x - \mu)^2}{2\sigma^2} \right) }</script>

<p>for $x \in \mathbb{R}$.</p>

<script type="math/tex; mode=display">\mathbb{E}(X) = \mu \quad \text{ and } \quad \mathbb{V}(X) = \sigma^2</script>

<h3 id="student-t">Student-t</h3>

<p>For $X \sim \text{StudentT}(\nu, \mu, \sigma)$ where $\nu &gt; 0$, $\mu
\in \mathbb{R}$, and $\sigma &gt; 0$, $X$ has probability density
function</p>

<script type="math/tex; mode=display">\text{studentT}(x | \nu, \mu, \sigma) = \frac{\Gamma((\nu + 1) /
2)}{\Gamma(\nu/2) \sqrt{\nu\pi\sigma^2}} \left( 1 +
\frac{1}{\nu}\left(\frac{y - \mu}{\sigma}\right)^2 \right)^{-(\nu+1)/2}</script>

<p>for $x \in \mathbb{R}$.</p>

<script type="math/tex; mode=display">\mathbb{E}(X) = \mu \quad \text{ and } \quad \mathbb{V}(X) = \sigma^2 \frac{\nu}{\nu - 2}</script>


              <nav class="c-page__nav">
  
    
    <a id="js-page__nav__prev" class="c-page__nav__prev" href="/bernoulli">
      〈 <span class="u-margin-right-tiny"></span> Bernoulli Distribution
    </a>
  

  
    
    <a id="js-page__nav__next" class="c-page__nav__next" href="/gamma">
      Gamma Distribution <span class="u-margin-right-tiny"></span> 〉
    </a>
  
</nav>

            </div>
          </div>
        </div>
      </main>
    </div>

  </body>
</html>
